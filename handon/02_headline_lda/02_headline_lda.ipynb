{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6062ebf7-8e27-423f-9601-70b513d906c4",
    "_execution_state": "idle",
    "_uuid": "644fe876d41b25011a0dc309f5cdee9f8c467698"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-695361520314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"../input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Any results you write to the current directory are saved as output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\A3\\envs\\intro-dl\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 316\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\A3\\envs\\intro-dl\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stdin'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\A3\\envs\\intro-dl\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    674\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\A3\\envs\\intro-dl\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "1b031c59-a5db-425d-9a03-be940c876c67",
    "_execution_state": "idle",
    "_uuid": "16fb6cfb0b94d305d3b773febf4a1649534d0748"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/abcnews-date-text.csv\",error_bad_lines=False,warn_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3925eef5-7e44-49e2-ac77-d1f5e485aaf8",
    "_execution_state": "idle",
    "_uuid": "b9c003574b4dc81f157036e4a76141926610dfb0"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a04f99be-fb3e-4bb1-b64c-799741987508",
    "_execution_state": "idle",
    "_uuid": "e5fe1dc63c9c1f6baec33c82dc52ac8935104851"
   },
   "outputs": [],
   "source": [
    "df.publish_date = pd.to_datetime(df.publish_date,format=\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1ba89a6-f293-47f5-9bd9-9af6480c5365",
    "_execution_state": "idle",
    "_uuid": "fdcc5e5d313bf778ee98668f5a69b599422a3a3d"
   },
   "outputs": [],
   "source": [
    "df.publish_date.min(),df.publish_date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c78c741-ff43-4959-b4c6-f6ffb6a7f9a4",
    "_execution_state": "idle",
    "_uuid": "f039e4cd1d2e7c6db4093bd22a17312c4411941b"
   },
   "outputs": [],
   "source": [
    "df.publish_date.max() - df.publish_date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ae6bee2-c9be-49cf-98dd-54e3700ed6cf",
    "_execution_state": "idle",
    "_uuid": "262a3700e0a2b05e2d560fc823ffd1438a1032bd"
   },
   "outputs": [],
   "source": [
    "len(df.publish_date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f7433627-04f5-40dc-b9b9-04796fe317de",
    "_execution_state": "idle",
    "_uuid": "1509315781762367b13d0925302a48df764f0c2c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = df.groupby('publish_date').tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e2db3e7-5f16-4714-bc73-5ab517e50d3e",
    "_execution_state": "idle",
    "_uuid": "b3625125831a5344b476fb551fa70f504ec5b542"
   },
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6500dd9e-3ed2-4f79-84c4-b14e75f7cbb6",
    "_execution_state": "idle",
    "_uuid": "7082c05ecd10591bb00dd9ac71e0215ad7d557f6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_headlines = s.headline_text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c4069cab-af9e-4ad2-b8bb-1cbd38b1506b",
    "_execution_state": "idle",
    "_uuid": "cb277662e5329419f42d51d204fc885d96132e27"
   },
   "source": [
    "## Get the sentiment for each headline and list positive , negative and neutral headlines separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5963aa2c-ee72-4d3a-a22a-cf3277a1374f",
    "_execution_state": "idle",
    "_uuid": "b80a32e84e44cecadb4f78d1bd2e3e14339c38b5"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from nltk.corpus import stopwords\n",
    "StopWords = stopwords.words(\"english\")\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "94568261-26a5-4c77-b60e-57c6bca00291",
    "_execution_state": "idle",
    "_uuid": "78048e18a56828ea2bb96899c7e7d7d4fc1b2c28"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sia = SIA()\n",
    "pos_list = []\n",
    "neg_list = []\n",
    "neu_list = []\n",
    "for post in all_headlines:\n",
    "    post = \" \".join([stemmer.stem(word) for word in str(post).lower().split() if word not in set(StopWords)])\n",
    "    res = sia.polarity_scores(post)\n",
    "    if res['compound'] > 0.0:\n",
    "        pos_list.append(post)\n",
    "    elif res['compound'] < 0.0:\n",
    "        neg_list.append(post)\n",
    "    else:\n",
    "        neu_list.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "755bd5ef-88fa-4a8e-9919-620c5ee6ad9d",
    "_execution_state": "idle",
    "_uuid": "7561c2329d0b414e1c90589d1172181e9efaeceb"
   },
   "outputs": [],
   "source": [
    "print(\"Number of Positive Headlines : {}\\nNumber of Negative Headlines : {}\\nNumber of Neutral Headlines : {}\".format(len(pos_list),len(neg_list),len(neu_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b99587cd-5d80-4625-bc3d-1493111bb049",
    "_execution_state": "idle",
    "_uuid": "5dc383b2550541d12a4f4d4f0c2d331e0a7763f6"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76056268-426c-4c99-bb84-040753cdc6ec",
    "_execution_state": "idle",
    "_uuid": "11c55ec3bf2e2530e42a1ea9b199c0f2b3564978"
   },
   "outputs": [],
   "source": [
    "pos_words = []\n",
    "for line in pos_list:\n",
    "    words = tokenizer.tokenize(line)\n",
    "    for w in words:\n",
    "        pos_words.append(w.lower())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36814346-fc19-4c7d-ac97-c14b45285630",
    "_execution_state": "idle",
    "_uuid": "4af8981bebba0c11251e929b660077e2c2e0726e"
   },
   "outputs": [],
   "source": [
    "neg_words = []\n",
    "for line in neg_list:\n",
    "    words = tokenizer.tokenize(line)\n",
    "    for w in words:\n",
    "        neg_words.append(w.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e28b453a-dc34-4749-85cb-5c8d8e5df9e2",
    "_execution_state": "idle",
    "_uuid": "c838b5739fa83129665da1bb8bdd319468b24465"
   },
   "source": [
    "## Most common positive words in the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f348777d-f062-46aa-bf17-ea5f4f0bee86",
    "_execution_state": "idle",
    "_uuid": "42dce2fdad24f0675a60111bf070eb285f1678a3"
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "pos_words = FreqDist(pos_words)\n",
    "for x in pos_words.most_common(10):\n",
    "    print(x[0],\":\",x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7f2cfcd-99e7-4f37-9a0f-c61d2ba91f56",
    "_execution_state": "idle",
    "_uuid": "79d649632fb9b875ba2049e22207faae25134c3b"
   },
   "source": [
    "## Most common negative words in the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a070d82f-3784-4ffc-a145-30298a05817d",
    "_execution_state": "idle",
    "_uuid": "178e2b673aefea37b45760a83e5346dc750af31c"
   },
   "outputs": [],
   "source": [
    "neg_words = FreqDist(neg_words)\n",
    "for x in neg_words.most_common(10):\n",
    "    print(x[0],\":\",x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5a68a97e-84ad-4a8d-ac03-89865d908656",
    "_execution_state": "idle",
    "_uuid": "1c8749d2038a4737bb5c91d58a6bdda4ee39523f"
   },
   "source": [
    "## Distribution of words in Positive Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6337f7ba-bd0d-4668-9f58-dbef309bbe6b",
    "_execution_state": "idle",
    "_uuid": "c7286e787617d651732043a31436bfa1ca3f547a"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['xtick.labelsize'] = 14\n",
    "plt.figure(figsize=(20,10))\n",
    "pos_words.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4d650270-f9c3-45eb-b915-2051ae255e40",
    "_execution_state": "idle",
    "_uuid": "cf84e00895c88995603e8089701a60649f3381b2"
   },
   "source": [
    "## Distribution of words in Negative Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2bc8276-1108-4f83-84d0-89c75e49cf7d",
    "_execution_state": "idle",
    "_uuid": "6488a404534820983e6e280bb7ea70cb1de3e52e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "neg_words.plot(50,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd2d5c75-6653-48e0-80bb-d49d0b68ab39",
    "_execution_state": "idle",
    "_uuid": "98ba92344e829359cee851af5822535e9184e9bb"
   },
   "source": [
    "####  The distribution is as expected, few words repeated most of the times in both positive and negative headlines. The frequency in case of Positive words dips quickly than Negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dba8a2eb-e5b4-4fd7-ad1e-3d4ef3deae62",
    "_execution_state": "idle",
    "_uuid": "00f25673e4394bde381f1f33282a083039df057f"
   },
   "source": [
    "## NEXT UP : CLUSTERING INTO TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ae820b38-9348-4760-8f19-061af7d4ea4b",
    "_execution_state": "idle",
    "_uuid": "20afad7fdcb9a45165fe6dfe7077fbc8e6d251aa"
   },
   "outputs": [],
   "source": [
    "sample = pos_list+neg_list+neu_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "670bd44a-d622-4edf-8503-c891d9b11541",
    "_uuid": "a275f8c9868ee12ac694b37808e0db6cfa8850fb"
   },
   "source": [
    "### Load gensim package for LDA and create a document-term matrix out of the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e529aa99-6676-4168-9d96-817104b281dd",
    "_execution_state": "idle",
    "_uuid": "5614f9d7d2a14ce6b22a9c0327d637877e42b815"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "sample_clean = [text.split() for text in sample] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0b693f7-ab27-4be4-bbcb-ee8a62e852a3",
    "_execution_state": "idle",
    "_uuid": "cf71c03594ba5c5539b38c186d4732892cbb4cc6"
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(sample_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in sample_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1701c639-9363-499e-aeb6-c472252871d2",
    "_uuid": "d4a345c1727cd4a43d73c04a82be953652e59cfc"
   },
   "source": [
    "### Fit a LDA model for the document-term matrix, number of topics is set to be 10. \n",
    "### If you have only few documents increasing passes might help and if the documents are small (sparse) increasing iterations should help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "181af15c-b37f-4075-b7f0-f5a3a821a0a7",
    "_execution_state": "idle",
    "_uuid": "233cca7e8fb392615cca4fa8c14a3c0dbc3b566d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "num_topics = 10\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50,iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2860fc06-377c-4fe0-84ca-1730c5f7ffb3",
    "_uuid": "bc3cccb0283e816fa33616763d3c7e9539824a53"
   },
   "source": [
    "### Get the Document-Topic distribution and Topic-Word distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0bd3343-3fbd-407a-83bf-33a6b17f4ac3",
    "_execution_state": "idle",
    "_uuid": "032ddc9e1c7686adabff4f1ae0d85cc8824c5208"
   },
   "outputs": [],
   "source": [
    "dtm = ldamodel.get_document_topics(doc_term_matrix)\n",
    "K = ldamodel.num_topics\n",
    "topic_word_matrix = ldamodel.print_topics(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f128b77c-1de2-4b17-9058-377f80a04c06",
    "_execution_state": "idle",
    "_uuid": "bf5f48e3c14063ecfbf991646483237ac2956f26"
   },
   "outputs": [],
   "source": [
    "print(\"The topics are: \\n\")\n",
    "for x in topic_word_matrix:\n",
    "    print(x[0],\":\",x[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "369230b5-6c30-4119-a9f5-9faa26efca36",
    "_uuid": "99567201430a12f52dd10eccb32f2a6f3c7bdf95"
   },
   "source": [
    "### Preparing the document-topic matrix for t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a6cf267-4979-4c2e-9d66-ef43a15f3189",
    "_execution_state": "idle",
    "_uuid": "30bee09d77753767825e64706d5eb3b567a203b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "608b2e05-0956-488d-ab40-cf0e003a3335",
    "_execution_state": "idle",
    "_uuid": "33251cd48cebecc1131f0cc6fb2e089a256d124a"
   },
   "outputs": [],
   "source": [
    "document_topic_matrix = matutils.corpus2dense(corpus=dtm,num_docs=len(all_headlines),num_terms=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "533f92f5-12ad-4db7-8307-b1524ebd295b",
    "_execution_state": "idle",
    "_uuid": "8b180cc06cfded93be7666528858ad2fa3945a05",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = document_topic_matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a8cb146-2bb3-4232-9747-d73a68b38de1",
    "_execution_state": "idle",
    "_uuid": "abc364dbe8d942e488281f4ab99b43754bee847f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0,init='pca',)\n",
    "\n",
    "# 8-D -> 2-D\n",
    "tsne_lda = tsne_model.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0a491b07-b270-4412-9200-cc6d26aab88b",
    "_execution_state": "idle",
    "_uuid": "d47e9a01773c6786f55def4b6ed56e4ebcee8beb"
   },
   "outputs": [],
   "source": [
    "_lda_keys = []\n",
    "for i in range(a.shape[0]):\n",
    "    _lda_keys.append(a[i].argmax())\n",
    "len(_lda_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5356955-c79b-4ba0-806d-50326217cd76",
    "_uuid": "1c43c36456e68bf99842fb7021fd401009dce6f4"
   },
   "source": [
    "### Using Bokeh to plot a interactive-visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a2d3a885-9376-4fba-b566-43f11836d39a",
    "_execution_state": "idle",
    "_uuid": "680f90b97cb81cba01716654a6d4b53cc8fcc9e4"
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show\n",
    "\n",
    "# 10 colors\n",
    "colormap = np.array([\"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\",\"#98df8a\", \"#d62728\", \"#ff9896\",\"#bcbd22\", \"#dbdb8d\"])\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e402ac4c-b676-4ddf-b944-3b9ac435987a",
    "_execution_state": "idle",
    "_uuid": "7be9bac73d39dec84eec7ff67728bab82fa1f79b"
   },
   "outputs": [],
   "source": [
    "plot_lda = bp.figure(plot_width=1000, plot_height=1000,\n",
    "                     title=\"LDA t-SNE Viz\",\n",
    "                     tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "                     x_axis_type=None, y_axis_type=None, min_border=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddd762f7-dfba-4de3-b492-e6a1568970ce",
    "_execution_state": "idle",
    "_uuid": "af9b679daa5f95067d8edae415a3b76444a13871"
   },
   "outputs": [],
   "source": [
    "n = len(a)\n",
    "plot_lda.scatter(x=tsne_lda[:, 0], y=tsne_lda[:, 1],\n",
    "                 color=colormap[_lda_keys][:n],\n",
    "                 source=bp.ColumnDataSource({\n",
    "                   \"content\": sample_clean[:n],\n",
    "                   \"topic_key\": _lda_keys[:n]\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd62c277-7ab2-4db1-a157-948dbdc169d4",
    "_uuid": "6d103f75a0247152ae72b9daacb174da61ba1346"
   },
   "source": [
    "### Annotate the graph with words from each topic. Below we are just setting the coordinats for the text and get the word distribution form topic-word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a960c4a7-fd45-4451-9ba2-1351c0eb7a6c",
    "_execution_state": "idle",
    "_uuid": "88279f558a3b4f43382d02396fc565f03978fe2b"
   },
   "outputs": [],
   "source": [
    "topic_summaries = [x[1] for x in topic_word_matrix]\n",
    "topic_coord = np.empty((a.shape[1], 2)) * np.nan\n",
    "for topic_num in _lda_keys:\n",
    "    topic_coord[topic_num] = tsne_lda[_lda_keys.index(topic_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c2fe8af8-b627-4455-81e6-5002f6ab8c8a",
    "_execution_state": "idle",
    "_uuid": "0b9abaf69a63ecef6ca07e285c8517edd1133814"
   },
   "outputs": [],
   "source": [
    "# add topic words to graph\n",
    "for i in range(a.shape[1]):\n",
    "    plot_lda.text(topic_coord[i, 0], topic_coord[i, 1], [topic_summaries[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0074e77f-b434-40d9-b1f2-2429c2e0aee5",
    "_execution_state": "idle",
    "_uuid": "61783b85b2664ca9aaaaa73294ed17c080de8f5d"
   },
   "outputs": [],
   "source": [
    "show(plot_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd4b2d04-2eb9-4b13-bf8a-eea38c35fe89",
    "_uuid": "85d14201b5efb4a4b6e2800e069d4e797d788a39"
   },
   "source": [
    "### The plot is really messy, reason should definitely be LDA model.. Each topic consist of similar words like \"world\",\"women\",\"australia\"..  For documents, the probablity of even most probable topic is also really low. Model can't distinguish documents into topics. Using more documents and tuning parameters should help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
